{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Environment Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "- Defines functions for loading and preprocessing images to be compatible with the EfficientNet model input requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and prepare the image\n",
    "def load_and_prepare_image(img_path, img_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.efficientnet.preprocess_input(img_array_expanded_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Decoding\n",
    "\n",
    "- Implements a function to decode model predictions into readable class names with their associated confidence scores, using the dataset directory to dynamically list class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode predictions\n",
    "def decode_predictions(predictions, top=3, dataset_path='./dataset'):\n",
    "    # Dynamically list the class names based on folder names in the dataset_path\n",
    "    class_names = sorted([dI for dI in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path,dI))])\n",
    "    results = []\n",
    "    for pred in predictions.numpy():\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [(class_names[i], pred[i]) for i in top_indices]\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading and Inference Setup\n",
    "\n",
    "- Loads the trained model and prepares it for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = './models/doodle_recognition'\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "infer = loaded_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions on a Set of Images\n",
    "\n",
    "- Processes a list of image paths, prepares each image, performs inference, and prints the top predictions for each image in the first set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of images to predict\n",
    "image_paths = ['./img/img1.png', './img/img2.png', './img/img3.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for ./img/img1.png: [[('dragon', 0.998961), ('mosquito', 0.00026180528), ('tiger', 0.00016646227)]]\n",
      "Predictions for ./img/img2.png: [[('brain', 0.4601192), ('bush', 0.2767019), ('broccoli', 0.20393847)]]\n",
      "Predictions for ./img/img3.png: [[('broccoli', 0.9135261), ('tree', 0.07400754), ('bear', 0.012262195)]]\n"
     ]
    }
   ],
   "source": [
    "for img_path in image_paths:\n",
    "    prepared_image = load_and_prepare_image(img_path)\n",
    "    pred_logits = infer(tf.constant(prepared_image))['dense']\n",
    "    top_predictions = decode_predictions(pred_logits, top=3)\n",
    "    print(f\"Predictions for {img_path}: {top_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repeats the prediction process for a second set of image paths, showcasing the model's ability to generalize across different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of images to predict\n",
    "image_paths = ['./img/img4.png', './img/img5.png', './img/img6.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for ./img/img4.png: [[('donut', 0.9994673), ('ear', 0.00015448373), ('flying saucer', 0.0001226513)]]\n",
      "Predictions for ./img/img5.png: [[('cruise ship', 0.902857), ('speedboat', 0.09713914), ('submarine', 3.038961e-06)]]\n",
      "Predictions for ./img/img6.png: [[('house', 0.99989223), ('barn', 5.0330505e-05), ('lantern', 2.9691857e-05)]]\n"
     ]
    }
   ],
   "source": [
    "for img_path in image_paths:\n",
    "    prepared_image = load_and_prepare_image(img_path)\n",
    "    pred_logits = infer(tf.constant(prepared_image))['dense']\n",
    "    top_predictions = decode_predictions(pred_logits, top=3)\n",
    "    print(f\"Predictions for {img_path}: {top_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epicity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
